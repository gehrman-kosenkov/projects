{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New file path: /Users/germankosenkov/Code projects/Crawling/3. Crawling Emails/New/TRK_imports/2024_Week_8.xlsx\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "import datetime\n",
    "import pickle\n",
    "import os.path\n",
    "import base64\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import os\n",
    "import openpyxl\n",
    "import mysql.connector\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import pymysql\n",
    "import mysql.connector\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "import requests\n",
    "\n",
    "# If modifying these SCOPES, delete the file token.pickle.\n",
    "SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']\n",
    "\n",
    "\n",
    "#Function to handle authentication and authorization to access the Gmail API using OAuth 2.0\n",
    "def get_gmail_service():\n",
    "    creds = None\n",
    "    # The file token.pickle stores the user's access and refresh tokens.\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            creds = pickle.load(token)\n",
    "    # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                '/Users/germankosenkov/Code projects/Crawling/3. Crawling Emails/New/client_secret_811893502700-tj4c2bv2942q1ua3459au95sc1ohoqle.apps.googleusercontent.com.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for the next run\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "\n",
    "    service = build('gmail', 'v1', credentials=creds)\n",
    "    return service\n",
    "\n",
    "#Function to search for a message using gmail address, attachment contained in the email etc. \n",
    "def search_messages(service, query):\n",
    "    result = service.users().messages().list(userId='me', q=query).execute()\n",
    "    messages = []\n",
    "    if 'messages' in result:\n",
    "        messages.extend(result['messages'])\n",
    "    return messages\n",
    "\n",
    "\n",
    "#Function to download a specific attachment from a Gmail message and saves it to a specified directory\n",
    "def get_attachments(service, message_id, store_dir, desired_filename):\n",
    "    try:\n",
    "        message = service.users().messages().get(userId='me', id=message_id).execute()\n",
    "        parts = message.get('payload', {}).get('parts', [])\n",
    "        for part in parts:\n",
    "            if part['filename'] == desired_filename:  # Check if the filename matches the desired one\n",
    "                if 'data' in part['body']:\n",
    "                    data = part['body']['data']\n",
    "                else:\n",
    "                    att_id = part['body'].get('attachmentId')\n",
    "                    att = service.users().messages().attachments().get(userId='me', messageId=message_id, id=att_id).execute()\n",
    "                    data = att['data']\n",
    "\n",
    "                file_data = base64.urlsafe_b64decode(data.encode('UTF-8'))\n",
    "                path = os.path.join(store_dir, part['filename'])\n",
    "\n",
    "                if not os.path.exists(store_dir):\n",
    "                    os.makedirs(store_dir)\n",
    "                with open(path, 'wb') as f:\n",
    "                    f.write(file_data)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "current_date = datetime.date.today()\n",
    "current_week = current_date.isocalendar()[1]\n",
    "previous_week = current_week - 1\n",
    "current_year = datetime.date.today().year\n",
    "\n",
    "new_file_path = ''\n",
    "\n",
    "\n",
    "def main():\n",
    "    service = get_gmail_service()\n",
    "    search_query = 'from:veysel_kaya@hotmail.com has:attachment filename:SUNSEEDMANGEMIVAGON20232024.xlsx'\n",
    "    messages = search_messages(service, search_query)\n",
    "\n",
    "    if messages:\n",
    "        latest_message = messages[0]  # Get the latest email\n",
    "\n",
    "        # Construct the path for saving the attachment with the week and year in the file name\n",
    "        #folder_name = f'{current_year}_Week_{previous_week}'\n",
    "        save_path = '/Users/germankosenkov/Code projects/Crawling/3. Crawling Emails/New/TRK_imports'\n",
    "        \n",
    "\n",
    "        # Call get_attachments with the desired filename\n",
    "        get_attachments(service, latest_message['id'], save_path, 'SUNSEEDMANGEMIVAGON20232024.xlsx')\n",
    "\n",
    "        # Path to the downloaded Excel file\n",
    "        old_file_path = os.path.join(save_path, 'SUNSEEDMANGEMIVAGON20232024.xlsx')\n",
    "        new_file_path = os.path.join(save_path, f'{current_year}_Week_{previous_week}.xlsx')\n",
    "\n",
    "        try:\n",
    "            # Rename the downloaded file\n",
    "            os.rename(old_file_path, new_file_path)\n",
    "            return new_file_path\n",
    "\n",
    "            # excel_data = pd.read_excel(new_file_path)\n",
    "            # print(excel_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading or renaming the Excel file: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    new_file_path = main()\n",
    "    print(f\"New file path: {new_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing existing data for 2023-07-31\n",
      "Replacing existing data for 2023-07-31\n",
      "Replacing existing data for 2023-07-31\n",
      "Replacing existing data for 2023-07-31\n",
      "Replacing existing data for 2023-08-31\n",
      "Replacing existing data for 2023-08-31\n",
      "Replacing existing data for 2023-08-31\n",
      "Replacing existing data for 2023-08-31\n",
      "Replacing existing data for 2023-08-31\n",
      "Replacing existing data for 2023-09-30\n",
      "Replacing existing data for 2023-09-30\n",
      "Replacing existing data for 2023-09-30\n",
      "Replacing existing data for 2023-09-30\n",
      "Replacing existing data for 2023-10-31\n",
      "Replacing existing data for 2023-10-31\n",
      "Replacing existing data for 2023-10-31\n",
      "Replacing existing data for 2023-11-30\n",
      "Replacing existing data for 2023-11-30\n",
      "Replacing existing data for 2023-11-30\n",
      "Replacing existing data for 2023-11-30\n",
      "Replacing existing data for 2023-12-31\n",
      "Replacing existing data for 2023-12-31\n",
      "Replacing existing data for 2023-12-31\n",
      "Replacing existing data for 2023-12-31\n",
      "Replacing existing data for 2023-12-31\n",
      "Replacing existing data for 2024-01-31\n",
      "Replacing existing data for 2024-01-31\n",
      "Replacing existing data for 2024-01-31\n",
      "Replacing existing data for 2024-01-31\n",
      "Replacing existing data for 2024-02-28\n",
      "Replacing existing data for 2024-02-28\n",
      "Replacing existing data for 2024-02-28\n",
      "-1 record(s) inserted.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The 'dates' list contains mappings of date labels as they appear in a crawled Excel file to their corresponding ISO 8601 formatted date strings. The date labels in the keys are in a mixed \n",
    "# format with Turkish and English month names followed by the year, while the values are the last day of the corresponding month in the YYYY-MM-DD format. This conversion is useful for:\n",
    "# 1. Clarity: The ISO 8601 date format (YYYY-MM-DD) is more standardized and easier to work with in data processing and database operations.\n",
    "# 2. Data Retrieval: Allows for easy and accurate retrieval of lines of data associated with each date from the Excel file.\n",
    "# 3. Database Insertion: Simplifies the process of inserting dates into databases, as the ISO format is widely accepted and used in most database systems.\n",
    "\n",
    "dates = [\n",
    "    {\"Temmuz/July 2023\": \"2023-07-31\"},\n",
    "    {\"Ağustos/August 2023\": \"2023-08-31\"},\n",
    "    {\"Eylül/September 2023\": \"2023-09-30\"},\n",
    "    {\"Ekim/October 2023\": \"2023-10-31\"},\n",
    "    {\"Kasım/November 2023\": \"2023-11-30\"},\n",
    "    {\"Aralık/December 2023\": \"2023-12-31\"},\n",
    "    {\"Ocak/January 2024\": \"2024-01-31\"},\n",
    "    {\"Şubat/February 2024\": \"2024-02-28\"},\n",
    "    {\"Mart/March 2024\": \"2024-03-31\"},\n",
    "    {\"Nisan/April 2024\": \"2024-04-30\"},\n",
    "    {\"Mayıs/May 2024\": \"2024-05-31\"},\n",
    "    {\"Haziran/June 2024\": \"2024-06-30\"}\n",
    "]\n",
    "\n",
    "# The 'countries' list contains mappings of country names as they appear in the crawled Excel file to their corresponding country codes used in the database. \n",
    "# The country names in the keys are in a mixed format with Turkish and English names followed by their ISO 3166-1 alpha-2 codes, while the values are the corresponding country codes \n",
    "# from the database. This conversion is necessary for:\n",
    "# 1. Consistency: Ensures that the country names from the Excel file match the standardized country codes in the database, maintaining consistency in the data representation.\n",
    "# 2. Data Retrieval: Allows for accurate retrieval of lines of data associated with each country from the Excel file.\n",
    "# 3. Database Insertion: Simplifies the process of inserting data into the database, as the country codes are standardized \n",
    "# 4. Despite the method being bulky, it is necessary to handle the varied country names and codes properly for seamless data integration between the Excel file and the database\n",
    "\n",
    "countries = [\n",
    "    {\"Ukrayna/UA\": 184},\n",
    "    {\"Rusya/RU\": 150},\n",
    "    {\"Moldova/MD\": 119},\n",
    "    {\"Romanya/RO\": 149},\n",
    "    {\"Avusturya/AT\": 14},\n",
    "    {\"Azerbaycan/AZ\": 15},\n",
    "    {\"Bahamas/BS\": 16},\n",
    "    {\"Bahreyn/BH\": 17},\n",
    "    {\"Bangladeş/BD\": 18},\n",
    "    {\"Barbados/BB\": 19},\n",
    "    {\"Belarus/BY\": 20},\n",
    "    {\"Belçika/BE\": 21},\n",
    "    {\"Belize/BZ\": 22},\n",
    "    {\"Benin/BJ\": 23},\n",
    "    {\"Bermuda/BM\": 24},\n",
    "    {\"Butan/BT\": 25},\n",
    "    {\"Bolivya/BO\": 26},\n",
    "    {\"Bosna Hersek/BOS\": 27},\n",
    "    {\"Botsvana/BW\": 28},\n",
    "    {\"Brezilya/BR\": 29},\n",
    "    {\"Bulgaristan/BG\": 30},\n",
    "    {\"Burkina Faso/BF\": 31},\n",
    "    {\"Burundi/BI\": 32},\n",
    "    {\"Kamboçya/KH\": 33},\n",
    "    {\"Kamerun/CM\": 34},\n",
    "    {\"Cayman Adaları/KY\": 35},\n",
    "    {\"Orta Afrika Cumhuriyeti/CF\": 36},\n",
    "    {\"Çad/TD\": 37},\n",
    "    {\"Şili/CL\": 38},\n",
    "    {\"Çin/CN\": 39},\n",
    "    {\"Kolombiya/CO\": 40},\n",
    "    {\"Komorlar/KM\": 41},\n",
    "    {\"Kongo DC/CD\": 42},\n",
    "    {\"Kosta Rika/CR\": 43},\n",
    "    {\"Hırvatistan/HR\": 44},\n",
    "    {\"Küba/CU\": 45},\n",
    "    {\"Kıbrıs/CY\": 46},\n",
    "    {\"Çek Cumhuriyeti/CZ\": 47},\n",
    "    {\"Danimarka/DK\": 48},\n",
    "    {\"Cibuti/DJ\": 49},\n",
    "    {\"Dominika/DM\": 50},\n",
    "    {\"Dominik Cumhuriyeti/DO\": 51},\n",
    "    {\"Ekvador/EC\": 52},\n",
    "    {\"Mısır/EG\": 53},\n",
    "    {\"El Salvador/SV\": 54},\n",
    "    {\"Ekvator Ginesi/GQ\": 55},\n",
    "    {\"Eritre/ER\": 56},\n",
    "    {\"Estonya/EE\": 57},\n",
    "    {\"Etiyopya/ET\": 58},\n",
    "    {\"Faroe Adaları/FO\": 59},\n",
    "    {\"Fiji/FJ\": 60},\n",
    "    {\"Finlandiya/FI\": 61},\n",
    "    {\"Fransa/FR\": 62},\n",
    "    {\"Gabon/GA\": 63},\n",
    "    {\"Gambiya/GM\": 64},\n",
    "    {\"Gürcistan/GEOR\": 65},\n",
    "    {\"Almanya/DE\": 66},\n",
    "    {\"Gana/GH\": 67},\n",
    "    {\"Cebelitarık/GI\": 68},\n",
    "    {\"Yunanistan/GR\": 69},\n",
    "    {\"Grönland/GL\": 70},\n",
    "    {\"Grenada/GD\": 71},\n",
    "    {\"Guam/GU\": 72},\n",
    "    {\"Guatemala/GT\": 73},\n",
    "    {\"Guyana/GY\": 74},\n",
    "    {\"Haiti/HT\": 75},\n",
    "    {\"Honduras/HN\": 76},\n",
    "    {\"Hong Kong SAR/HK\": 77},\n",
    "    {\"Macaristan/HU\": 78},\n",
    "    {\"İzlanda/IS\": 79},\n",
    "    {\"Hindistan/IN\": 80},\n",
    "    {\"Endonezya/ID\": 81},\n",
    "    {\"İran/IR\": 82},\n",
    "    {\"Irak/IQ\": 83},\n",
    "    {\"İrlanda/IE\": 84},\n",
    "    {\"İsrail/IL\": 85},\n",
    "    {\"İtalya/IT\": 86},\n",
    "    {\"Jamaika/JM\": 87},\n",
    "    {\"Japonya/JP\": 88},\n",
    "    {\"Ürdün/JO\": 89},\n",
    "    {\"Kazakistan/KZ\": 90},\n",
    "    {\"Kenya/KE\": 91},\n",
    "    {\"Kiribati/KI\": 92},\n",
    "    {\"Güney Kore/KR\": 93},\n",
    "    {\"Kosova/XK\": 94},\n",
    "    {\"Kuveyt/KW\": 95},\n",
    "    {\"Kırgızistan/KG\": 96},\n",
    "    {\"Laos/LA\": 97},\n",
    "    {\"Letonya/LV\": 98},\n",
    "    {\"Lübnan/LB\": 99},\n",
    "    {\"Lesotho/LS\": 100},\n",
    "    {\"Liberya/LR\": 101},\n",
    "    {\"Libya/LY\": 102},\n",
    "    {\"Lihtenştayn/LI\": 103},\n",
    "    {\"Litvanya/LT\": 104},\n",
    "    {\"Lüksemburg/LU\": 105},\n",
    "    {\"Macao SAR/MO\": 106},\n",
    "    {\"Madagaskar/MG\": 107},\n",
    "    {\"Malavi/MW\": 108},\n",
    "    {\"Malezya/MY\": 109},\n",
    "    {\"Maldivler/MV\": 110},\n",
    "    {\"Mali/ML\": 111},\n",
    "    {\"Malta/MT\": 112},\n",
    "    {\"Marshall Adaları/MH\": 113},\n",
    "    {\"Moritanya/MR\": 114},\n",
    "    {\"Mauritius/MU\": 115},\n",
    "    {\"Meksika/MX\": 116},\n",
    "    {\"Moldova/MD\": 117},\n",
    "    {\"Monako/MC\": 118},\n",
    "    {\"Mongolistan/MN\": 119},\n",
    "    {\"Karadağ/ME\": 120},\n",
    "    {\"Fas/MA\": 121},\n",
    "    {\"Mozambik/MZ\": 122},\n",
    "    {\"Myanmar/MM\": 123},\n",
    "    {\"Namibya/NA\": 124},\n",
    "    {\"Nauru/NR\": 125},\n",
    "    {\"Nepal/NP\": 126},\n",
    "    {\"Hollanda/NL\": 127},\n",
    "    {\"Yeni Kaledonya/NC\": 128},\n",
    "    {\"Yeni Zelanda/NZ\": 129},\n",
    "    {\"Nikaragua/NI\": 130},\n",
    "    {\"Nijer/NE\": 131},\n",
    "    {\"Nijerya/NG\": 132},\n",
    "    {\"Norveç/NO\": 133},\n",
    "    {\"Umman/OM\": 134},\n",
    "    {\"Pakistan/PK\": 135},\n",
    "    {\"Palau/PW\": 136},\n",
    "    {\"Panama/PA\": 137},\n",
    "    {\"Papua Yeni Gine/PG\": 138},\n",
    "    {\"Paraguay/PY\": 139},\n",
    "    {\"Peru/PE\": 140},\n",
    "    {\"Filipinler/PH\": 141},\n",
    "    {\"Polonya/PL\": 142},\n",
    "    {\"Portekiz/PT\": 143},\n",
    "    {\"Porto Riko/PR\": 144},\n",
    "    {\"Katar/QA\": 145},\n",
    "    {\"Romanya/RO\": 146},\n",
    "    {\"Ruanda/RW\": 148},\n",
    "    {\"Saint Kitts ve Nevis/KN\": 149},\n",
    "    {\"Saint Lucia/LC\": 150},\n",
    "    {\"Saint Vincent ve Grenadinler/VC\": 151},\n",
    "    {\"Saint Pierre ve Miquelon/PM\": 152},\n",
    "    {\"Samoa/WS\": 153},\n",
    "    {\"San Marino/SM\": 154},\n",
    "    {\"Sao Tome ve Principe/ST\": 155},\n",
    "    {\"Suudi Arabistan/SA\": 156},\n",
    "    {\"Senegal/SN\": 157},\n",
    "    {\"Sırbistan/SER\": 158},\n",
    "    {\"Seyşeller/SC\": 159},\n",
    "    {\"Sierra Leone/SL\": 160},\n",
    "    {\"Singapur/SG\": 161},\n",
    "    {\"Slovakya/SK\": 162},\n",
    "    {\"Slovenya/SI\": 163},\n",
    "    {\"Solomon Adaları/SB\": 164},\n",
    "    {\"Somali/SO\": 165},\n",
    "    {\"Güney Afrika/ZA\": 166},\n",
    "    {\"İspanya/ES\": 167},\n",
    "    {\"Sri Lanka/LK\": 168},\n",
    "    {\"Sudan/SD\": 169},\n",
    "    {\"Surinam/SR\": 170},\n",
    "    {\"Svaziland/SZ\": 171},\n",
    "    {\"İsveç/SE\": 172},\n",
    "    {\"İsviçre/CH\": 173},\n",
    "    {\"Suriye/SY\": 174},\n",
    "    {\"Tayvan/TW\": 175},\n",
    "    {\"Tacikistan/TJ\": 176},\n",
    "    {\"Tanzanya/TZ\": 177},\n",
    "    {\"Tayland/TH\": 178},\n",
    "    {\"Togo/TG\": 179},\n",
    "    {\"Tonga/TO\": 180},\n",
    "    {\"Trinidad ve Tobago/TT\": 181},\n",
    "    {\"Tunus/TN\": 182},\n",
    "    {\"Türkiye/TR\": 183},\n",
    "    {\"Türkmenistan/TM\": 184},\n",
    "    {\"Tuvalu/TV\": 185},\n",
    "    {\"Uganda/UG\": 186},\n",
    "    {\"Birleşik Arap Emirlikleri/AE\": 188},\n",
    "    {\"Uruguay/UY\": 189},\n",
    "    {\"Özbekistan/UZ\": 190},\n",
    "    {\"Vanuatu/VU\": 191},\n",
    "    {\"Venezuela/VE\": 192},\n",
    "    {\"Vietnam/VN\": 193},\n",
    "    {\"Virgin Adaları, Britanya/VG\": 194},\n",
    "    {\"Virgin Adaları, Amerika/VI\": 195},\n",
    "    {\"Yemen/YE\": 196},\n",
    "    {\"Zambiya/ZM\": 197},\n",
    "    {\"Zimbabve/ZW\": 198},\n",
    "    {\"Avrupa 28/EU-28\": 199},\n",
    "    {\"Avrupa 27/EU-27\": 200},\n",
    "    {\"Birleşik Krallık/UK\": 201},\n",
    "    {\"Küresel Süt Ticareti/GDT\": 202},\n",
    "    {\"Fransa - ATLA/ATLA\": 203},\n",
    "    {\"Beneluks/BE-NE-LU\": 204},\n",
    "    {\"Küresel/Global\": 205},\n",
    "    {\"Doğu AB/East-EU\": 206},\n",
    "    {\"LATAM/LATAM\": 207},\n",
    "    {\"Okyanusya/Oceania\": 208},\n",
    "    {\"ABD CLS raporu/US CLS report\": 209},\n",
    "    {\"ABD - NDP/United States - NDP\": 210},\n",
    "    {\"Cape Verde/CV\": 211},\n",
    "    {\"Brunei/BN\": 212},\n",
    "    {\"Cook Adaları/CK\": 213},\n",
    "    {\"Fildişi Sahili/CI\": 214},\n",
    "    {\"Fransız Polinezyası/PF\": 215},\n",
    "    {\"Gine/GN\": 216},\n",
    "    {\"Gine-Bissau/GW\": 217},\n",
    "    {\"Kuzey Kore/KP\": 218},\n",
    "    {\"Mayotte/YT\": 219},\n",
    "    {\"Mikronezya/FS\": 220},\n",
    "    {\"Saint Kitts ve Nevis/KN\": 221},\n",
    "    {\"Saint Lucia/LC\": 222},\n",
    "    {\"Saint Vincent ve Grenadinler/VC\": 223},\n",
    "    {\"Saint Pierre ve Miquelon/PM\": 224},\n",
    "    {\"Samoa/WS\": 225},\n",
    "    {\"Swaziland/SZ\": 226},\n",
    "    {\"Doğu Timor/TL\": 227},\n",
    "    {\"Wallis ve Futuna Adaları/WF\": 228},\n",
    "    {\"Belirsiz/Unspecified\": 229},\n",
    "    {\"Avrupa Ekonomik Alanı/EEA\": 230},\n",
    "    {\"Britanya Hint Okyanusu Toprakları/IO\": 231},\n",
    "    {\"Fransız Güney Toprakları/TF\": 232},\n",
    "    {\"Asya/Asia\": 233},\n",
    "    {\"Mercosur/Mercosur\": 234},\n",
    "    {\"Orta Doğu/Middle East\": 235},\n",
    "    {\"Kuzey Afrika/North Africa\": 236},\n",
    "    {\"Kuzey Amerika/North America\": 237},\n",
    "    {\"Güney Amerika/South America\": 238},\n",
    "    {\"Orta Amerika/Central America\": 239},\n",
    "    {\"Kuzeydoğu Asya/Northeast Asia\": 240},\n",
    "    {\"Merkez Güney Asya/Central South Asia\": 241},\n",
    "    {\"Güneydoğu Asya/Southeast Asia\": 242},\n",
    "    {\"EAEB/EAEU\": 243},\n",
    "    {\"Sahra Altı Afrika/Sub-saharan Africa\": 244},\n",
    "    {\"Dünya/World\": 245},\n",
    "    {\"ABD (Ortabatı)/United States (Midwest)\": 246},\n",
    "    {\"ABD (Kuzeydoğu)/United States (Northeast)\": 247},\n",
    "    {\"ABD (Güney)/United States (South)\": 248},\n",
    "    {\"ABD (Batı)/United States (West)\": 249},\n",
    "    {\"Batı AB/West-EU\": 250}\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "#Connect to the database into which to insert the data from the crawled excel file using SSHTunnelForwarder\n",
    "b_ssh_host = '18.195.40.197'\n",
    "b_ssh_user = 'forge'\n",
    "b_ssh_port = 22\n",
    "b_ssh_private_key = '/Users/germankosenkov/.ssh/id_rsa'\n",
    "b_sql_hostname = 'gehrman.ccq0tjftm3pw.eu-central-1.rds.amazonaws.com'\n",
    "b_sql_username = 'gehrman'\n",
    "b_sql_password = 'ycEqAKjqFZH3sH'\n",
    "b_sql_database = 'vesper'\n",
    "b_sql_port = 3306\n",
    "\n",
    "with SSHTunnelForwarder(\n",
    "        (b_ssh_host, b_ssh_port),\n",
    "        ssh_username=b_ssh_user,\n",
    "        ssh_pkey=b_ssh_private_key,\n",
    "        remote_bind_address=(b_sql_hostname, b_sql_port)) as tunnel:\n",
    "\n",
    "    b_conn = mysql.connector.connect(\n",
    "        host='127.0.0.1',\n",
    "        user=b_sql_username,\n",
    "        passwd=b_sql_password,\n",
    "        db=b_sql_database,\n",
    "        port=tunnel.local_bind_port\n",
    "    )\n",
    "\n",
    "    b_cursor = b_conn.cursor()\n",
    "\n",
    "    # Path to the Excel file\n",
    "    workbook = openpyxl.load_workbook(new_file_path, data_only=True)\n",
    "    # Select the sheet to extract data from\n",
    "    sheet = workbook['TOPLAM']  # You can also specify the sheet name like this: sheet = workbook['Sheet1']\n",
    "\n",
    "    # Iterate through the rows and extract data from columns month,quantity,country_of_origin\n",
    "    for row in sheet.iter_rows(min_row=2, values_only=True):\n",
    "        # Assuming columns A, B, and C correspond to index 0, 1, and 2\n",
    "        month = row[5]#changed\n",
    "        quantity = row[6]\n",
    "        country_of_origin = row[7]\n",
    "\n",
    "        #column_b_value = row[5]#changed\n",
    "        #column_c_value = row[6]\n",
    "        #column_d_value = row[7]\n",
    "\n",
    "        # Check if the values are not headers and not None\n",
    "        if month and quantity and country_of_origin:\n",
    "            if month != \"Ay\" and quantity != \"Miktar\" and country_of_origin != \"Ülke\":\n",
    "                # Find the corresponding date and country values from dictionaries\n",
    "                for date_dict in dates:\n",
    "                    for key, value in date_dict.items():\n",
    "                        if key == month:\n",
    "                            month = value\n",
    "                            break\n",
    "\n",
    "                for country_dict in countries:\n",
    "                    for key, value in country_dict.items():\n",
    "                        if key == country_of_origin:\n",
    "                            country_of_origin = value\n",
    "                            break\n",
    "\n",
    "                #Before inserting check if the data already exists in the table\n",
    "                #If exists we will update the row as in the new coming files data can be revised by the source\n",
    "                #if data doesn't exist we insert a new row \n",
    "                check_data_query = \"SELECT * FROM TradeData WHERE product_id = %s AND date = %s AND raw_trade_quantity = %s AND origin_country_id = %s AND destination_country_id_raw = %s AND data_source_id = %s\"\n",
    "                val = (859, month, quantity, country_of_origin, 180, 4)\n",
    "                b_cursor.execute(check_data_query, val)\n",
    "                existing_data = b_cursor.fetchone() \n",
    "\n",
    "                try:\n",
    "                    b_conn.autocommit = False\n",
    "\n",
    "                    if existing_data:\n",
    "                        print(\"Replacing existing data for\", month)\n",
    "                        update_query = \"UPDATE TradeData SET raw_trade_quantity = %s, destination_country_id_raw = %s, origin_country_id = %s, trade_quantity = %s, raw_unit = %s, unit = %s, frequency = %s WHERE product_id = %s AND date = %s AND data_source_id = %s AND destination_country_id_raw = %s AND origin_country_id = %s\"\n",
    "                        update_values = (quantity, 180, country_of_origin, quantity, 'mt', 'mt', 'monthly', 859, month, 4, 180, country_of_origin)\n",
    "                        b_cursor.execute(update_query, update_values)\n",
    "                    else:\n",
    "                        print(\"Inserting data for\", month)\n",
    "                        insert_query = \"INSERT INTO TradeData (product_id, date, raw_trade_quantity, destination_country_id_raw, origin_country_id, trade_quantity, raw_unit, unit, data_source_id, frequency) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "                        insert_values = (859, month, quantity, 180, country_of_origin, quantity, 'mt', 'mt', 4, 'monthly')\n",
    "                        b_cursor.execute(insert_query, insert_values)\n",
    "\n",
    "                    b_conn.commit()  # Commit the transaction\n",
    "                \n",
    "                except Exception as e:\n",
    "                    b_conn.rollback()  # Rollback the transaction if an error occurs\n",
    "                    print(\"Error occurred:\", e)\n",
    "\n",
    "                finally:\n",
    "                    b_conn.autocommit = True\n",
    "\n",
    "\n",
    "    b_cursor.close()\n",
    "    b_conn.close()\n",
    "\n",
    "print(b_cursor.rowcount, \"record(s) inserted.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 18:29:29) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a44830708761a843059adba6d554183630a5ed8b6adc3257bd6953cce1e327da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
