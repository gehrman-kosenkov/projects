{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import pandas as pd\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "from itertools import product\n",
    "import nest_asyncio\n",
    "from constants import years, commodity_codes\n",
    "\n",
    "nest_asyncio.apply()  # This line allows asyncio.run() to be called in Jupyter or similar environments\n",
    "\n",
    "\n",
    "successful_results = []\n",
    "failed_results = []\n",
    "\n",
    "headers = CaseInsensitiveDict()\n",
    "headers[\"Accept\"] = \"application/json\"\n",
    "headers[\"API_KEY\"] = \"68F6B0D6-444E-43C0-A4E1-64CF5D3710B7\"\n",
    "\n",
    "DELAY_BETWEEN_BATCHES = 0.5  # Define the delay\n",
    "\n",
    "async def fetch_data(session, year, commodity_code):\n",
    "    try:\n",
    "        url = f\"https://apps.fas.usda.gov/PSDOnlineDataServices/api/CommodityData/GetCommodityDataByYear?commodityCode={commodity_code}&marketYear={year}\"\n",
    "        async with session.get(url, headers=headers) as resp:\n",
    "            # print(f\"Year {year}, Commodity {commodity_code}: {resp.status}\")\n",
    "            if resp.status == 200:\n",
    "                data = await resp.json()\n",
    "                df = pd.DataFrame(data)\n",
    "                # print(f\"Data for Year {year}, Commodity {commodity_code}:\")\n",
    "                # print(df)\n",
    "                return df, None\n",
    "            else:\n",
    "                return None, f\"Failed to fetch data for year {year}, commodity {commodity_code} with status {resp.status}\"\n",
    "    except Exception as e:\n",
    "        return None, str(e)\n",
    "\n",
    "async def main():\n",
    "    global successful_results, failed_results\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for year, commodity_code in product(years, commodity_codes):\n",
    "            task = asyncio.ensure_future(fetch_data(session, year, commodity_code))\n",
    "            tasks.append(task)\n",
    "            await asyncio.sleep(DELAY_BETWEEN_BATCHES)\n",
    "        \n",
    "        results = await asyncio.gather(*tasks)\n",
    "\n",
    "    successful_results = [result for result, error in results if result is not None]\n",
    "    failed_results = [error for result, error in results if error is not None]\n",
    "\n",
    "# Run the main function\n",
    "await main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Database connection credentials\n",
    "\n",
    "b_ssh_host = X\n",
    "b_ssh_user = X\n",
    "b_ssh_port = X\n",
    "b_ssh_private_key = X\n",
    "b_sql_hostname = X\n",
    "b_sql_username = X\n",
    "b_sql_password = X\n",
    "b_sql_database = X\n",
    "b_sql_port = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define query structure\n",
    "\n",
    "def query_data(ssh_host, ssh_user, ssh_port, ssh_private_key, sql_hostname, sql_username, sql_password, sql_database, sql_port, query):\n",
    "    with SSHTunnelForwarder(\n",
    "            (ssh_host, ssh_port),\n",
    "            ssh_username=ssh_user,\n",
    "            ssh_pkey=ssh_private_key,\n",
    "            remote_bind_address=(sql_hostname, sql_port)) as tunnel:\n",
    "        conn = pymysql.connect(\n",
    "            host='127.0.0.1',\n",
    "            user=sql_username,\n",
    "            passwd=sql_password,\n",
    "            db=sql_database,\n",
    "            port=tunnel.local_bind_port\n",
    "        )\n",
    "        data = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "from pymysql import IntegrityError, OperationalError\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "from dateutil import relativedelta\n",
    "import json\n",
    "import traceback\n",
    "import logging\n",
    "\n",
    "from constants import country_name_exceptions, mapping\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.CRITICAL)  # Set to CRITICAL during the insertion process to minimize overhead\n",
    "\n",
    "try:\n",
    "    with SSHTunnelForwarder(\n",
    "            (b_ssh_host, b_ssh_port),\n",
    "            ssh_username=b_ssh_user,\n",
    "            ssh_pkey=b_ssh_private_key,\n",
    "            remote_bind_address=(b_sql_hostname, b_sql_port)) as tunnel:\n",
    "        \n",
    "        b_conn = pymysql.connect(\n",
    "            host='127.0.0.1',\n",
    "            user=b_sql_username,\n",
    "            passwd=b_sql_password,\n",
    "            db=b_sql_database,\n",
    "            port=tunnel.local_bind_port\n",
    "        )\n",
    "        \n",
    "        b_cursor = b_conn.cursor()\n",
    "\n",
    "        try:\n",
    "            query = \"SELECT id, name FROM countries\"\n",
    "            country_df = pd.read_sql(query, b_conn)\n",
    "            country_df['name'] = country_df['name'].str.strip()\n",
    "            country_mapping = dict(zip(country_df['name'], country_df['id']))\n",
    "            source_id = 4\n",
    "\n",
    "            aggregated_results = []\n",
    "\n",
    "            for df in successful_results:\n",
    "                # Map commodity codes\n",
    "                df['CommodityCode'] = df['CommodityCode'].str.strip()\n",
    "                df['CommodityCode'] = df['CommodityCode'].map(mapping)\n",
    "                \n",
    "                # Normalize and map country names\n",
    "                df['CountryName'] = df['CountryName'].str.strip().replace(country_name_exceptions)\n",
    "                df['CountryId'] = df['CountryName'].map(country_mapping).astype(pd.Int64Dtype())\n",
    "                \n",
    "                # Normalize and convert values\n",
    "                df['Value'] = df['Value'].astype(float)\n",
    "                mask = df['UnitDescription'].str.strip() == '(1000 MT)'\n",
    "                df.loc[mask, 'Value'] *= 1000\n",
    "                df['MarketYear'] = df['MarketYear'].astype(int)\n",
    "                df['Value'] = df['Value'].round(2)\n",
    "                df.loc[mask, 'UnitDescription'] = 'MT'\n",
    "\n",
    "                # Check for unmapped countries\n",
    "                unmapped_countries = df[df['CountryId'].isna()]['CountryName'].unique()\n",
    "                if len(unmapped_countries) > 0:\n",
    "                    print(\"Unmapped Countries:\", unmapped_countries)\n",
    "                \n",
    "                aggregated_results.append(df)\n",
    "\n",
    "            # Concatenate results\n",
    "            if aggregated_results:\n",
    "                final_result = pd.concat(aggregated_results, ignore_index=True)\n",
    "                print(final_result)\n",
    "            else:\n",
    "                print(\"No data to aggregate.\")\n",
    "\n",
    "            # Batch insert using executemany\n",
    "            sql = \"INSERT INTO annual_data_PSD (product_id, country_code, market_year, attribute_id, unit_id, amount, source_id) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "            values = [\n",
    "                (\n",
    "                    row[\"CommodityCode\"], row[\"CountryId\"], row[\"MarketYear\"], row[\"AttributeId\"], row[\"UnitId\"], row[\"Value\"], source_id\n",
    "                )\n",
    "                for index, row in final_result.iterrows()\n",
    "            ]\n",
    "            b_cursor.executemany(sql, values)\n",
    "            b_conn.commit()  \n",
    "            b_conn.close()\n",
    "\n",
    "        except IntegrityError as ie:\n",
    "            logger.error(f\"Integrity error occurred: {ie}\")\n",
    "            b_conn.rollback()\n",
    "            logger.info(\"Transaction rolled back due to IntegrityError.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"An unexpected error occurred during query execution: {e}\")\n",
    "            b_conn.rollback()\n",
    "            logger.info(\"Transaction rolled back due to an unexpected error.\")\n",
    "\n",
    "        finally:\n",
    "            b_cursor.close()\n",
    "            logger.info(\"Cursor closed.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.critical(f\"Critical error in establishing SSH Tunnel: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a44830708761a843059adba6d554183630a5ed8b6adc3257bd6953cce1e327da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
