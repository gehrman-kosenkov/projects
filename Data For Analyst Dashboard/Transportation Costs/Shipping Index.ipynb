{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Index\n",
      "0  2024-08-15  619.0\n",
      "1  2024-08-14  615.0\n",
      "2  2024-08-13  599.0\n",
      "3  2024-08-12  605.0\n",
      "4  2024-08-09  622.0\n",
      "5  2024-08-08  647.0\n",
      "6  2024-08-07  665.0\n",
      "7  2024-08-06  693.0\n",
      "8  2024-08-05  724.0\n",
      "9  2024-08-02  755.0\n",
      "10 2024-08-01  760.0\n",
      "11 2024-07-31  778.0\n",
      "12 2024-07-30  796.0\n",
      "13 2024-07-29  806.0\n",
      "14 2024-07-26  814.0\n",
      "15 2024-07-25  814.0\n",
      "16 2024-07-24  816.0\n",
      "17 2024-07-23  817.0\n",
      "18 2024-07-22  822.0\n",
      "19 2024-07-19  822.0\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "# Set up the web driver in headless mode\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--headless\") \n",
    "chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument('--ignore-certificate-errors')\n",
    "chrome_options.add_argument('--allow-running-insecure-content')\n",
    "chrome_options.add_argument(\"--disable-extensions\")\n",
    "chrome_options.add_argument(\"--proxy-bypass-list=*\")\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument(\"--proxy-server='direct://'\")\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument(\"--disable-software-rasterizer\")\n",
    "download_directory = \"/Users/germankosenkov/Code projects/Crawling/Crawling Malaysian Data\"\n",
    "chrome_options.add_experimental_option(\"prefs\", {\n",
    "    \"download.default_directory\": download_directory\n",
    "})\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "try:\n",
    "    # Navigate to the webpage containing the table\n",
    "    url = \"https://en.stockq.org/index/BCTI.php\"\n",
    "    driver.get(url)\n",
    "\n",
    "    # Get the page source and parse it with BeautifulSoup\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    # Find the table and extract data\n",
    "    table = soup.select_one('center:nth-of-type(5) table')\n",
    "    \n",
    "    if table:\n",
    "        rows = table.find_all('tr')\n",
    "        data = []\n",
    "        for row in rows:\n",
    "            cells = row.find_all('td')\n",
    "            cell_data = [cell.get_text(strip=True) for cell in cells]\n",
    "            data.append(cell_data)\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        # Assuming your DataFrame is called df\n",
    "        df.columns = ['Date', 'Index', 'Change', 'Date', 'Index', 'Change']\n",
    "        df = df.drop(0)\n",
    "\n",
    "        left_side = df.iloc[:, :3]  \n",
    "        right_side = df.iloc[:, 3:]\n",
    "        df_stacked = pd.concat([left_side, right_side], ignore_index=True)\n",
    "\n",
    "        df_stacked['Date'] = pd.to_datetime(df_stacked['Date'], errors='coerce')\n",
    "        df_stacked = df_stacked.drop(columns=['Change'])\n",
    "        df_stacked['Index'] = pd.to_numeric(df_stacked['Index'], errors='coerce').round(2)\n",
    "\n",
    "        print(df_stacked)\n",
    "\n",
    "    else:\n",
    "        print(\"Table not found\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "finally:\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sshtunnel import SSHTunnelForwarder\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "from datetime import datetime, timedelta\n",
    "import traceback\n",
    "from dateutil import relativedelta\n",
    "import json as json \n",
    "\n",
    "\n",
    "b_ssh_host = X\n",
    "b_ssh_user = X\n",
    "b_ssh_port = X\n",
    "b_ssh_private_key = X\n",
    "b_sql_hostname = X\n",
    "b_sql_username = X\n",
    "b_sql_password = X\n",
    "b_sql_database = X\n",
    "b_sql_port = X\n",
    "\n",
    "def query_data(ssh_host, ssh_user, ssh_port, ssh_private_key, sql_hostname, sql_username, sql_password, sql_database, sql_port, query):\n",
    "    with SSHTunnelForwarder(\n",
    "            (ssh_host, ssh_port),\n",
    "            ssh_username=ssh_user,\n",
    "            ssh_pkey=ssh_private_key,\n",
    "            remote_bind_address=(sql_hostname, sql_port)) as tunnel:\n",
    "        conn = pymysql.connect(\n",
    "            host='X',\n",
    "            user=sql_username,\n",
    "            passwd=sql_password,\n",
    "            db=sql_database,\n",
    "            port=tunnel.local_bind_port\n",
    "        )\n",
    "        data = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pymysql import IntegrityError, OperationalError\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import pymysql\n",
    "\n",
    "# Configure logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)  # Reduce logging level to minimize overhead\n",
    "\n",
    "# File handler to log detailed debug info\n",
    "file_handler = logging.FileHandler('debug.log')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "file_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(file_formatter)\n",
    "\n",
    "# Console handler to log only errors or higher\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.ERROR)\n",
    "console_formatter = logging.Formatter('%(levelname)s - %(message)s')\n",
    "console_handler.setFormatter(console_formatter)\n",
    "\n",
    "# Add handlers to the logger\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "# Define the batch size\n",
    "BATCH_SIZE = 1000  # Adjust the batch size based on your needs\n",
    "\n",
    "source_id = 3\n",
    "index_name = 'BCTI'\n",
    "\n",
    "def chunker(seq, size):\n",
    "    \"\"\"Generator to divide data into chunks.\"\"\"\n",
    "    for pos in range(0, len(seq), size):\n",
    "        yield seq[pos:pos + size]\n",
    "\n",
    "try:\n",
    "    with SSHTunnelForwarder(\n",
    "            (b_ssh_host, b_ssh_port),\n",
    "            ssh_username=b_ssh_user,\n",
    "            ssh_pkey=b_ssh_private_key,\n",
    "            remote_bind_address=(b_sql_hostname, b_sql_port)) as tunnel:\n",
    "        \n",
    "        logger.info(\"SSH Tunnel established successfully.\")\n",
    "        \n",
    "        try:\n",
    "            b_conn = pymysql.connect(\n",
    "                host='127.0.0.1',\n",
    "                user=b_sql_username,\n",
    "                passwd=b_sql_password,\n",
    "                db=b_sql_database,\n",
    "                port=tunnel.local_bind_port\n",
    "            )\n",
    "            logger.info(\"Database connection established successfully.\")\n",
    "            b_cursor = b_conn.cursor()\n",
    "\n",
    "            try:\n",
    "\n",
    "\n",
    "                inserting_query = '''INSERT IGNORE INTO freight \n",
    "                                     (date, index_size, index_name, source_id) \n",
    "                                     VALUES (%s, %s, %s, %s)'''\n",
    "\n",
    "                # Prepare the list of values\n",
    "                values = [\n",
    "                    (\n",
    "                        item['Date'], item['Index'], index_name, source_id\n",
    "                    )\n",
    "                    for index, item in df_stacked.iterrows()\n",
    "                ]\n",
    "\n",
    "                # Insert in batches\n",
    "                for i, chunk in enumerate(chunker(values, BATCH_SIZE)):\n",
    "                    logger.info(f\"Inserting batch {i + 1} of {len(values) // BATCH_SIZE + 1}\")\n",
    "                    b_cursor.executemany(inserting_query, chunk)\n",
    "                    b_conn.commit()\n",
    "                    logger.info(f\"Batch {i + 1} committed successfully.\")\n",
    "\n",
    "            except IntegrityError as ie:\n",
    "                logger.error(f\"Integrity error occurred: {ie}\")\n",
    "                b_conn.rollback()\n",
    "                logger.info(\"Transaction rolled back due to IntegrityError.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"An unexpected error occurred during query execution: {e}\")\n",
    "                b_conn.rollback()\n",
    "                logger.info(\"Transaction rolled back due to an unexpected error.\")\n",
    "\n",
    "            finally:\n",
    "                b_cursor.close()\n",
    "                logger.info(\"Cursor closed.\")\n",
    "\n",
    "        except OperationalError as oe:\n",
    "            logger.error(f\"Operational error occurred: {oe}\")\n",
    "\n",
    "        finally:\n",
    "            b_conn.close()\n",
    "            logger.info(\"Database connection closed.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.critical(f\"Critical error in establishing SSH Tunnel: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a44830708761a843059adba6d554183630a5ed8b6adc3257bd6953cce1e327da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
