{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sshtunnel import SSHTunnelForwarder\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "from datetime import datetime, timedelta\n",
    "import traceback\n",
    "from dateutil import relativedelta\n",
    "import json as json \n",
    "\n",
    "#Connection credentials for databases A and B\n",
    "a_ssh_host = X\n",
    "a_ssh_user = X\n",
    "a_ssh_port = X\n",
    "a_ssh_private_key = X\n",
    "a_sql_hostname = X\n",
    "a_sql_username = X\n",
    "a_sql_password = X\n",
    "a_sql_database = X\n",
    "a_sql_port = X\n",
    " \n",
    "b_ssh_host = X\n",
    "b_ssh_user = X\n",
    "b_ssh_port = \n",
    "b_ssh_private_key = X\n",
    "b_sql_hostname = X\n",
    "b_sql_username = X\n",
    "b_sql_password = X\n",
    "b_sql_database = X\n",
    "b_sql_port = X\n",
    "\n",
    "#Define query structure \n",
    "def query_data(ssh_host, ssh_user, ssh_port, ssh_private_key, sql_hostname, sql_username, sql_password, sql_database, sql_port, query):\n",
    "    with SSHTunnelForwarder(\n",
    "            (ssh_host, ssh_port),\n",
    "            ssh_username=ssh_user,\n",
    "            ssh_pkey=ssh_private_key,\n",
    "            remote_bind_address=(sql_hostname, sql_port)) as tunnel:\n",
    "        conn = pymysql.connect(\n",
    "            host='127.0.0.1',\n",
    "            user=sql_username,\n",
    "            passwd=sql_password,\n",
    "            db=sql_database,\n",
    "            port=tunnel.local_bind_port\n",
    "        )\n",
    "        data = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pymysql import IntegrityError, OperationalError\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import pymysql\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Configure logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)  # Reduce logging level to minimize overhead\n",
    "\n",
    "# File handler to log detailed debug info\n",
    "file_handler = logging.FileHandler('debug.log')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "file_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(file_formatter)\n",
    "\n",
    "# Console handler to log only errors or higher\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.ERROR)\n",
    "console_formatter = logging.Formatter('%(levelname)s - %(message)s')\n",
    "console_handler.setFormatter(console_formatter)\n",
    "\n",
    "# Add handlers to the logger\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "# Define the batch size\n",
    "BATCH_SIZE = 1000  \n",
    "\n",
    "def chunker(seq, size):\n",
    "    \"\"\"Generator to divide data into chunks.\"\"\"\n",
    "    for pos in range(0, len(seq), size):\n",
    "        yield seq[pos:pos + size]\n",
    "\n",
    "\n",
    "try:\n",
    "    with SSHTunnelForwarder(\n",
    "            (b_ssh_host, b_ssh_port),\n",
    "            ssh_username=b_ssh_user,\n",
    "            ssh_pkey=b_ssh_private_key,\n",
    "            remote_bind_address=(b_sql_hostname, b_sql_port)) as tunnel:\n",
    "        \n",
    "        logger.info(\"SSH Tunnel established successfully.\")\n",
    "        \n",
    "        try:\n",
    "            b_conn = pymysql.connect(\n",
    "                host='127.0.0.1',\n",
    "                user=b_sql_username,\n",
    "                passwd=b_sql_password,\n",
    "                db=b_sql_database,\n",
    "                port=tunnel.local_bind_port\n",
    "            )\n",
    "            logger.info(\"Database connection established successfully.\")\n",
    "            b_cursor = b_conn.cursor()\n",
    "\n",
    "            #retrieve the data from the database A\n",
    "            try:\n",
    "                query_1 = '''SELECT base_currency,target_currency,rate,date\n",
    "                            FROM exchange_rates\n",
    "                            WHERE base_currency = 'USD' AND target_currency IN ('MYR','UAH','RUB','BRL','EUR', 'PHP')\n",
    "                            AND date > '2014-12-31'\n",
    "                            '''\n",
    "                \n",
    "                logger.info(f\"Executing query: {query_1}\")\n",
    "                results = query_data(a_ssh_host, a_ssh_user, a_ssh_port, a_ssh_private_key,\n",
    "                                     a_sql_hostname, a_sql_username, a_sql_password, a_sql_database, a_sql_port, query_1)\n",
    "                logger.info(f\"Query executed successfully, retrieved {len(results)} rows.\")\n",
    "\n",
    "                #insert the data into the database B\n",
    "                inserting_query = '''INSERT IGNORE exchange_rates\n",
    "                                     (base_currency,target_currency,rate,date,source_id)\n",
    "                                     VALUES (%s, %s, %s, %s, %s)'''\n",
    "                \n",
    "\n",
    "                source_id = 1\n",
    "\n",
    "\n",
    "                values = [\n",
    "                            (\n",
    "                                item['base_currency'],\n",
    "                                item['target_currency'],\n",
    "                                item['rate'],\n",
    "                                item['date'],\n",
    "                                source_id\n",
    "                            )\n",
    "                            for index, item in results.iterrows()\n",
    "                        ]\n",
    "\n",
    "\n",
    "                # Insert in batches\n",
    "                for i, chunk in enumerate(chunker(values, BATCH_SIZE)):\n",
    "                    logger.info(f\"Inserting batch {i + 1} of {len(values) // BATCH_SIZE + 1}\")\n",
    "                    b_cursor.executemany(inserting_query, chunk)\n",
    "                    b_conn.commit()\n",
    "                    logger.info(f\"Batch {i + 1} committed successfully.\")\n",
    "\n",
    "            except IntegrityError as ie:\n",
    "                logger.error(f\"Integrity error occurred: {ie}\")\n",
    "                b_conn.rollback()\n",
    "                logger.info(\"Transaction rolled back due to IntegrityError.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"An unexpected error occurred during query execution: {e}\")\n",
    "                b_conn.rollback()\n",
    "                logger.info(\"Transaction rolled back due to an unexpected error.\")\n",
    "\n",
    "            finally:\n",
    "                b_cursor.close()\n",
    "                logger.info(\"Cursor closed.\")\n",
    "\n",
    "        except OperationalError as oe:\n",
    "            logger.error(f\"Operational error occurred: {oe}\")\n",
    "\n",
    "        finally:\n",
    "            b_conn.close()\n",
    "            logger.info(\"Database connection closed.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.critical(f\"Critical error in establishing SSH Tunnel: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a44830708761a843059adba6d554183630a5ed8b6adc3257bd6953cce1e327da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
