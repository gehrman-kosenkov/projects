
To support our data modeling efforts, I needed to download several hundred files from a website that was both slow and prone to errors.

Since the website lacks a bulk download feature, I developed a script to handle the process overnight.

This script automated the entire workflow: logging into the site, applying the necessary filters, searching for and downloading the files to the appropriate directory, 
and renaming them as needed. 

It also included a mechanism to refresh the website to address any potential bugs.
