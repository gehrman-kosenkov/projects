{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2024 WASDE Release Dates (12:00pm ET)\n",
    "#Aug. 12, Sep. 12, Oct. 11, Nov. 8, Dec. 10\n",
    "\n",
    "#add data for 2024! \n",
    "#add global data! \n",
    "#think about how to avoid duplications \n",
    "#when new data comes insert only for 2022,2023, and 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import pandas as pd\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "from itertools import product\n",
    "import nest_asyncio\n",
    "from constants import years, commodity_codes\n",
    "\n",
    "nest_asyncio.apply()  # This line allows asyncio.run() to be called in Jupyter or similar environments\n",
    "\n",
    "\n",
    "successful_results = []\n",
    "failed_results = []\n",
    "\n",
    "headers = CaseInsensitiveDict()\n",
    "headers[\"Accept\"] = \"application/json\"\n",
    "headers[\"API_KEY\"] = \"68F6B0D6-444E-43C0-A4E1-64CF5D3710B7\"\n",
    "\n",
    "DELAY_BETWEEN_BATCHES = 0.5  # Define the delay\n",
    "\n",
    "async def fetch_data(session, year, commodity_code):\n",
    "    try:\n",
    "        url = f\"https://apps.fas.usda.gov/PSDOnlineDataServices/api/CommodityData/GetWorldCommodityDataByYear?commodityCode={commodity_code}&marketYear={year}\"\n",
    "        async with session.get(url, headers=headers) as resp:\n",
    "            # print(f\"Year {year}, Commodity {commodity_code}: {resp.status}\")\n",
    "            if resp.status == 200:\n",
    "                data = await resp.json()\n",
    "                df = pd.DataFrame(data)\n",
    "                # print(f\"Data for Year {year}, Commodity {commodity_code}:\")\n",
    "                # print(df)\n",
    "                return df, None\n",
    "            else:\n",
    "                return None, f\"Failed to fetch data for year {year}, commodity {commodity_code} with status {resp.status}\"\n",
    "    except Exception as e:\n",
    "        return None, str(e)\n",
    "\n",
    "async def main():\n",
    "    global successful_results, failed_results\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for year, commodity_code in product(years, commodity_codes):\n",
    "            task = asyncio.ensure_future(fetch_data(session, year, commodity_code))\n",
    "            tasks.append(task)\n",
    "            await asyncio.sleep(DELAY_BETWEEN_BATCHES)\n",
    "        \n",
    "        results = await asyncio.gather(*tasks)\n",
    "\n",
    "    successful_results = [result for result, error in results if result is not None]\n",
    "    failed_results = [error for result, error in results if error is not None]\n",
    "\n",
    "# Run the main function\n",
    "await main()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_ssh_host = '18.195.40.197'\n",
    "b_ssh_user = 'forge'\n",
    "b_ssh_port = 22\n",
    "b_ssh_private_key = '/Users/germankosenkov/.ssh/id_rsa'\n",
    "b_sql_hostname = 'gehrman.ccq0tjftm3pw.eu-central-1.rds.amazonaws.com'\n",
    "b_sql_username = 'gehrman'\n",
    "b_sql_password = 'ycEqAKjqFZH3sH'\n",
    "b_sql_database = 'vesper'\n",
    "b_sql_port = 3306"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_data(ssh_host, ssh_user, ssh_port, ssh_private_key, sql_hostname, sql_username, sql_password, sql_database, sql_port, query):\n",
    "    with SSHTunnelForwarder(\n",
    "            (ssh_host, ssh_port),\n",
    "            ssh_username=ssh_user,\n",
    "            ssh_pkey=ssh_private_key,\n",
    "            remote_bind_address=(sql_hostname, sql_port)) as tunnel:\n",
    "        conn = pymysql.connect(\n",
    "            host='127.0.0.1',\n",
    "            user=sql_username,\n",
    "            passwd=sql_password,\n",
    "            db=sql_database,\n",
    "            port=tunnel.local_bind_port\n",
    "        )\n",
    "        data = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "from pymysql import IntegrityError, OperationalError\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "from dateutil import relativedelta\n",
    "import json\n",
    "import traceback\n",
    "import logging\n",
    "from constants import mapping\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.CRITICAL)  # Set to CRITICAL during the insertion process to minimize overhead\n",
    "\n",
    "country_id = 264\n",
    "\n",
    "try:\n",
    "    with SSHTunnelForwarder(\n",
    "            (b_ssh_host, b_ssh_port),\n",
    "            ssh_username=b_ssh_user,\n",
    "            ssh_pkey=b_ssh_private_key,\n",
    "            remote_bind_address=(b_sql_hostname, b_sql_port)) as tunnel:\n",
    "        \n",
    "        b_conn = pymysql.connect(\n",
    "            host='127.0.0.1',\n",
    "            user=b_sql_username,\n",
    "            passwd=b_sql_password,\n",
    "            db=b_sql_database,\n",
    "            port=tunnel.local_bind_port\n",
    "        )\n",
    "        \n",
    "        b_cursor = b_conn.cursor()\n",
    "\n",
    "        try:\n",
    "            # query = \"SELECT id, name FROM countries\"\n",
    "            # country_df = pd.read_sql(query, b_conn)\n",
    "            # country_df['name'] = country_df['name'].str.strip()\n",
    "            # country_mapping = dict(zip(country_df['name'], country_df['id']))\n",
    "            source_id = 4\n",
    "\n",
    "            aggregated_results = []\n",
    "\n",
    "            for df in successful_results:\n",
    "                # Map commodity codes\n",
    "                df['CommodityCode'] = df['CommodityCode'].str.strip()\n",
    "                df['CommodityCode'] = df['CommodityCode'].map(mapping)\n",
    "                \n",
    "                # # Normalize and map country names\n",
    "                # df['CountryName'] = df['CountryName'].str.strip().replace(country_name_exceptions)\n",
    "                # df['CountryId'] = df['CountryName'].map(country_mapping).astype(pd.Int64Dtype())\n",
    "                \n",
    "                # Normalize and convert values\n",
    "                df['Value'] = df['Value'].astype(float)\n",
    "                mask = df['UnitDescription'].str.strip() == '(1000 MT)'\n",
    "                df.loc[mask, 'Value'] *= 1000\n",
    "                df['MarketYear'] = df['MarketYear'].astype(int)\n",
    "                df['Value'] = df['Value'].round(2)\n",
    "                df.loc[mask, 'UnitDescription'] = 'MT'\n",
    "\n",
    "                # # Check for unmapped countries\n",
    "                # unmapped_countries = df[df['CountryId'].isna()]['CountryName'].unique()\n",
    "                # if len(unmapped_countries) > 0:\n",
    "                #     print(\"Unmapped Countries:\", unmapped_countries)\n",
    "                \n",
    "                aggregated_results.append(df)\n",
    "\n",
    "            # Concatenate results\n",
    "            if aggregated_results:\n",
    "                final_result = pd.concat(aggregated_results, ignore_index=True)\n",
    "                # print(final_result)\n",
    "            else:\n",
    "                print(\"No data to aggregate.\")\n",
    "\n",
    "            # Batch insert using executemany\n",
    "            sql = \"INSERT INTO annual_data_PSD (product_id, country_code, market_year, attribute_id, unit_id, amount, source_id) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "            values = [\n",
    "                (\n",
    "                    row[\"CommodityCode\"], country_id, row[\"MarketYear\"], row[\"AttributeId\"], row[\"UnitId\"], row[\"Value\"], source_id\n",
    "                )\n",
    "                for index, row in final_result.iterrows()\n",
    "            ]\n",
    "            b_cursor.executemany(sql, values)\n",
    "            b_conn.commit()  \n",
    "            b_conn.close()\n",
    "\n",
    "        except IntegrityError as ie:\n",
    "            logger.error(f\"Integrity error occurred: {ie}\")\n",
    "            b_conn.rollback()\n",
    "            logger.info(\"Transaction rolled back due to IntegrityError.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"An unexpected error occurred during query execution: {e}\")\n",
    "            b_conn.rollback()\n",
    "            logger.info(\"Transaction rolled back due to an unexpected error.\")\n",
    "\n",
    "        finally:\n",
    "            b_cursor.close()\n",
    "            logger.info(\"Cursor closed.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.critical(f\"Critical error in establishing SSH Tunnel: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2024 WASDE Release Dates (12:00pm ET)\n",
    "#Aug. 12, Sep. 12, Oct. 11, Nov. 8, Dec. 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a44830708761a843059adba6d554183630a5ed8b6adc3257bd6953cce1e327da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
